{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b292a996-b993-4151-9592-b03c5ba791b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import torch\n",
    "import string\n",
    "import tensorflow\n",
    "from sklearn.metrics  import classification_report ,confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0706cd7f-b2ed-4f54-a400-e0d1555ae6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a07cb8b6-d344-4683-bc13-9bfd3f99961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DatentrÃ¤ger in Laufwerk D: ist Volume\n",
      " Volumeseriennummer: 7AA8-B5E4\n",
      "\n",
      " Verzeichnis von D:\\uni\\ai\\NLP_sentiment_analysis\n",
      "\n",
      "04.01.2025  15:59    <DIR>          .\n",
      "04.01.2025  15:59    <DIR>          ..\n",
      "03.01.2025  14:28                66 .gitattributes\n",
      "03.01.2025  16:40             3Â 256 .gitignore\n",
      "04.01.2025  15:57    <DIR>          .ipynb_checkpoints\n",
      "04.01.2025  11:47    <DIR>          anaconda_projects\n",
      "03.01.2025  16:35         3Â 999Â 092 firstTry.keras\n",
      "04.01.2025  15:59             7Â 391 LIME.ipynb\n",
      "04.01.2025  15:42           135Â 371 Messner_Pfandler_sentiment_analysis.ipynb\n",
      "04.01.2025  02:41           155Â 695 Messner_Pfandler_sentiment_analysis_firstModel.ipynb\n",
      "03.01.2025  21:45         3Â 999Â 093 model_d30000_b128_e7.keras\n",
      "03.01.2025  14:28                27 README.md\n",
      "21.09.2019  01:36       238Â 803Â 811 training.1600000.processed.noemoticon.csv\n",
      "               9 Datei(en),    247Â 103Â 802 Bytes\n",
      "               4 Verzeichnis(se), 503Â 537Â 168Â 384 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d455ae80-02e8-47b9-932e-1292759a3430",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: firstTry.keras/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirstTry.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:186\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    184\u001b[0m   filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[0;32m    185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath, \u001b[38;5;28mcompile\u001b[39m, options)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable) or SavedModel.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:110\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (path_to_pbtxt, \u001b[38;5;28mstr\u001b[39m(e)))\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    111\u001b[0m                 (export_dir,\n\u001b[0;32m    112\u001b[0m                  constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m    113\u001b[0m                  constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB))\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: firstTry.keras/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('firstTry.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c508f-993e-4183-a2a3-1922ce9c8e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
