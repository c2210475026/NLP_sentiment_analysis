{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8c10d904-83f9-4452-bba5-f8137eeb08f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import string\n",
    "import tensorflow\n",
    "from sklearn.metrics  import classification_report ,confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f8ca1fce-dd30-48b6-9d6e-85e9bcd22615",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\", engine=\"python\")\n",
    "data.columns = [\"label\", \"id\", \"date\", \"query\", \"username\", \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "30e35526-f0c0-421e-908d-342a937c7b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          id                          date     query       username  \\\n",
       "0      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4      0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                                text  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ad0a007c-0550-45f4-a58b-e36c0a1c6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "81bde87c-c2c6-4774-8313-581dcce5a80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  is upset that he can't update his Facebook by ...      0\n",
       "1  @Kenichan I dived many times for the ball. Man...      0\n",
       "2    my whole body feels itchy and like its on fire       0\n",
       "3  @nationwideclass no, it's not behaving at all....      0\n",
       "4                      @Kwesidei not the whole crew       0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "124e4c3d-dc65-4287-b153-52df66a22586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d3fcf99b-b0a8-4a17-b205-1da881f6ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 1599999\n"
     ]
    }
   ],
   "source": [
    "print('data length:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cec1941c-65f4-4557-8ba8-079a7fcaf531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 2)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "58617553-5304-406e-a193-412556b4f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                       text  label\n",
       "0        is upset that he can't update his Facebook by ...      0\n",
       "1        @Kenichan I dived many times for the ball. Man...      0\n",
       "2          my whole body feels itchy and like its on fire       0\n",
       "3        @nationwideclass no, it's not behaving at all....      0\n",
       "4                            @Kwesidei not the whole crew       0\n",
       "...                                                    ...    ...\n",
       "1599994  Just woke up. Having no school is the best fee...      4\n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...      4\n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...      4\n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...      4\n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...      4\n",
       "\n",
       "[1599999 rows x 2 columns]>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bd6c53ab-53f9-472b-adfd-f382902f93c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     object\n",
       "label     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f43d7a6e-908c-488d-abdf-6964133a9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['label']==4, 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "173bbc6f-6890-49d6-b5bf-b1c2ae82c771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                       text  label\n",
       "0        is upset that he can't update his Facebook by ...      0\n",
       "1        @Kenichan I dived many times for the ball. Man...      0\n",
       "2          my whole body feels itchy and like its on fire       0\n",
       "3        @nationwideclass no, it's not behaving at all....      0\n",
       "4                            @Kwesidei not the whole crew       0\n",
       "...                                                    ...    ...\n",
       "1599994  Just woke up. Having no school is the best fee...      1\n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...      1\n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...      1\n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...      1\n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...      1\n",
       "\n",
       "[1599999 rows x 2 columns]>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b625f3dd-9f79-48ac-bda1-81e5272525df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    800000\n",
       "0    799999\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4ea0141a-9939-4333-a512-d24b17ee5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data[data['label'] == 1]\n",
    "data_neg = data[data['label'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f307dcb-84e9-4c7e-ba6c-62dbebbe4522",
   "metadata": {},
   "source": [
    "DATASET REDUCTION for TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b204e3f4-484a-4d51-9a42-a7ed6936b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data_pos.iloc[:int(80000)]\n",
    "data_neg = data_neg.iloc[:int(80000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "32e96fa1-9152-4acf-8f5b-dd047c09fe3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    20000\n",
       "0    20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_pos, data_neg])\n",
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f9d09-f8d7-41ad-89df-17fc7b909d2d",
   "metadata": {},
   "source": [
    "TEXT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "60fe4fc9-8564-43ba-b316-42172c20d55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                      text  label\n",
       "799999       I LOVE @Health4UandPets u guys r the best!!       1\n",
       "800000  im meeting up with one of my besties tonight! ...      1\n",
       "800001  @DaRealSunisaKim Thanks for the Twitter add, S...      1\n",
       "800002  Being sick can be really cheap when it hurts t...      1\n",
       "800003    @LovesBrooklyn2 he has that effect on everyone       1\n",
       "...                                                   ...    ...\n",
       "19995                           One more day of holidays       0\n",
       "19996   feeling so down right now .. i hate you DAMN H...      0\n",
       "19997   geez,i hv to READ the whole book of personalit...      0\n",
       "19998   I threw my sign at donnie and he bent over to ...      0\n",
       "19999   @heather2711 Good thing I didn't find any then...      0\n",
       "\n",
       "[40000 rows x 2 columns]>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1368a94-c77b-4f5a-b663-9ea3c2206769",
   "metadata": {},
   "source": [
    "Abkürzungen ausschreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4d7c3d4a-14f3-4c5d-bd9f-a6acfc1b403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_word = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'ATK': 'At The Keyboard',\n",
    "    'ATM': 'At The Moment',\n",
    "    'A3': 'Anytime, Anywhere, Anyplace',\n",
    "    'BAK': 'Back At Keyboard',\n",
    "    'BBL': 'Be Back Later',\n",
    "    'BBS': 'Be Back Soon',\n",
    "    'BFN': 'Bye For Now',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BRT': 'Be Right There',\n",
    "    'BTW': 'By The Way',\n",
    "    'B4': 'Before',\n",
    "    'CU': 'See You',\n",
    "    'CUL8R': 'See You Later',\n",
    "    'CYA': 'See You',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FC': 'Fingers Crossed',\n",
    "    'FWIW': \"For What It's Worth\",\n",
    "    'FYI': 'For Your Information',\n",
    "    'GAL': 'Get A Life',\n",
    "    'GG': 'Good Game',\n",
    "    'GN': 'Good Night',\n",
    "    'GMTA': 'Great Minds Think Alike',\n",
    "    'GR8': 'Great!',\n",
    "    'G9': 'Genius',\n",
    "    'IC': 'I See',\n",
    "    'ICQ': 'I Seek you (also a chat program)',\n",
    "    'ILU': 'ILU: I Love You',\n",
    "    'IMHO': 'In My Honest/Humble Opinion',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'IOW': 'In Other Words',\n",
    "    'IRL': 'In Real Life',\n",
    "    'KISS': 'Keep It Simple, Stupid',\n",
    "    'LDR': 'Long Distance Relationship',\n",
    "    'LMAO': 'Laugh My A.. Off',\n",
    "    'LOL': 'Laughing Out Loud',\n",
    "    'LTNS': 'Long Time No See',\n",
    "    'L8R': 'Later',\n",
    "    'MTE': 'My Thoughts Exactly',\n",
    "    'M8': 'Mate',\n",
    "    'NRN': 'No Reply Necessary',\n",
    "    'OIC': 'Oh I See',\n",
    "    'PITA': 'Pain In The A..',\n",
    "    'PRT': 'Party',\n",
    "    'PRW': 'Parents Are Watching',\n",
    "    'QPSA?': 'Que Pasa?',\n",
    "    'ROFL': 'Rolling On The Floor Laughing',\n",
    "    'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "    'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
    "    'SK8': 'Skate',\n",
    "    'STATS': 'Your sex and age',\n",
    "    'ASL': 'Age, Sex, Location',\n",
    "    'THX': 'Thank You',\n",
    "    'TTFN': 'Ta-Ta For Now!',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'R': 'ARE',\n",
    "    'U': 'You',\n",
    "    'U2': 'You Too',\n",
    "    'U4E': 'Yours For Ever',\n",
    "    'WB': 'Welcome Back',\n",
    "    'WTF': 'What The F...',\n",
    "    'WTG': 'Way To Go!',\n",
    "    'WUF': 'Where Are You From?',\n",
    "    'W8': 'Wait...',\n",
    "    '7K': 'Sick:-D Laugher',\n",
    "    'TFW': 'That feeling when',\n",
    "    'MFW': 'My face when',\n",
    "    'MRW': 'My reaction when',\n",
    "    'IFYP': 'I feel your pain',\n",
    "    'TNTL': 'Trying not to laugh',\n",
    "    'JK': 'Just kidding',\n",
    "    'IDC': \"I don't care\",\n",
    "    'ILY': 'I love you',\n",
    "    'IMU': 'I miss you',\n",
    "    'ADIH': 'Another day in hell',\n",
    "    'ZZZ': 'Sleeping, bored, tired',\n",
    "    'WYWH': 'Wish you were here',\n",
    "    'TIME': 'Tears in my eyes',\n",
    "    'BAE': 'Before anyone else',\n",
    "    'FIMH': 'Forever in my heart',\n",
    "    'BSAAW': 'Big smile and a wink',\n",
    "    'BWL': 'Bursting with laughter',\n",
    "    'BFF': 'Best friends forever',\n",
    "    'CSL': \"Can't stop laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "86d9d720-860d-471c-bb2d-ff550dc15225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999      I LOVE @Health4UandPets You guys ARE the best!!\n",
       "800000    im meeting up with one of my besties tonight! ...\n",
       "800001    @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800002    Being sick can be really cheap when it hurts t...\n",
       "800003       @LovesBrooklyn2 he has that effect on everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def short_conv(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_word:\n",
    "            new_text.append(chat_word[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "data['text'] = data['text'].apply(lambda text: short_conv(text))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b8d0d-45cf-4531-acf4-9fc107348a7a",
   "metadata": {},
   "source": [
    "Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b8f8bb89-9b83-4895-851c-cc747f7d50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text'] = data['text'].apply(lambda text: TextBlob(text).correct().string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "20e528d5-624d-4d21-84c1-f1611d63e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0098cf-f49d-408c-a232-fe8459057477",
   "metadata": {},
   "source": [
    "LOWERCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a1b942d0-f008-4d10-ae9e-7c2c7644addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999      i love @health4uandpets you guys are the best!!\n",
       "800000    im meeting up with one of my besties tonight! ...\n",
       "800001    @darealsunisakim thanks for the twitter add, s...\n",
       "800002    being sick can be really cheap when it hurts t...\n",
       "800003       @lovesbrooklyn2 he has that effect on everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']=data['text'].str.lower()\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "80c255da-34be-4cc4-9f26-bcf1489d1893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "edc4398d-0cf2-4db9-9553-541f7ac1b6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999                    love @health4uandpets guys best!!\n",
       "800000    im meeting one besties tonight! cant wait!! - ...\n",
       "800001    @darealsunisakim thanks twitter add, sunisa! g...\n",
       "800002    sick really cheap hurts much eat real food plu...\n",
       "800003                      @lovesbrooklyn2 effect everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "data['text'] = data['text'].apply(lambda text: cleaning_stopwords(text))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e5735-5f12-4ab3-acf4-f97de8ef0d1b",
   "metadata": {},
   "source": [
    "REMOVING USERNAME, URL, HASHTAGS and Non-Alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "17cdb69b-dfad-4fb2-aa6e-d36fee1bffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "userPattern = r\"@[^\\s]+\"\n",
    "#hastagPattern = r\"#[^\\s]+\"\n",
    "alphaPattern = r\"[^a-zA-Z]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1b2fbda4-df52-4158-928f-bb3fb66b8e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999                                    love  guys best  \n",
       "800000    im meeting one besties tonight  cant wait     ...\n",
       "800001     thanks twitter add  sunisa  got meet hin show...\n",
       "800002    sick really cheap hurts much eat real food plu...\n",
       "800003                                      effect everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda text: re.sub(userPattern,'', text))\n",
    "#data['text'] = data['text'].apply(lambda text: re.sub(hastagPattern,'',text))\n",
    "data['text'] = data['text'].apply(lambda text: re.sub(urlPattern,'',text))\n",
    "data['text'] = data['text'].apply(lambda text: re.sub(alphaPattern,' ', text))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc159eec-a39b-4f69-89eb-1fe143b6c7f6",
   "metadata": {},
   "source": [
    "REMOVE PUNCTUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "dd5e7ec7-0b96-40e2-886b-70ec4e3c6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "72ce048b-8194-4033-8a42-1bcafaf0fa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999                                    love  guys best  \n",
       "800000    im meeting one besties tonight  cant wait     ...\n",
       "800001     thanks twitter add  sunisa  got meet hin show...\n",
       "800002    sick really cheap hurts much eat real food plu...\n",
       "800003                                      effect everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']= data['text'].apply(lambda x: cleaning_punctuations(x))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75719127-3d24-40dc-9cb9-201ddbad2248",
   "metadata": {},
   "source": [
    "Removing Sequences of 3 or more Identical Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a83f278a-8183-4352-b767-9f0302fe4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencePattern = r\"(.)\\1\\1+\"\n",
    "seqReplacePattern = r\"\\1\\1\"\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(sequencePattern, seqReplacePattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f6179e73-3991-4083-b5a2-17c36806a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999                                    love  guys best  \n",
       "800000    im meeting one besties tonight  cant wait  gir...\n",
       "800001     thanks twitter add  sunisa  got meet hin show...\n",
       "800002    sick really cheap hurts much eat real food plu...\n",
       "800003                                      effect everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: cleaning_repeating_char(x))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98f4b8-ba1e-4bac-9551-43a4ed91f83c",
   "metadata": {},
   "source": [
    "TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "25eddf59-241e-4fb2-a5ba-69c7a9453521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999                                   [love, guys, best]\n",
       "800000    [im, meeting, one, besties, tonight, cant, wai...\n",
       "800001    [thanks, twitter, add, sunisa, got, meet, hin,...\n",
       "800002    [sick, really, cheap, hurts, much, eat, real, ...\n",
       "800003                                   [effect, everyone]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "data['text'] = data['text'].apply(tokenizer.tokenize)\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7ccbc-b822-4373-b14c-b0ce2ef637b2",
   "metadata": {},
   "source": [
    "STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "378d82ee-ae96-47d1-8165-6adf60a8feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "\n",
    "#data['text']= data['text'].apply(lambda x: stemming_on_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c233859-7578-4dfb-bf51-61789241e763",
   "metadata": {},
   "source": [
    "LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "29314d44-4165-4339-9470-999478826fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799999                                    [love, guy, best]\n",
       "800000    [im, meeting, one, besties, tonight, cant, wai...\n",
       "800001    [thanks, twitter, add, sunisa, get, meet, hin,...\n",
       "800002    [sick, really, cheap, hurt, much, eat, real, f...\n",
       "800003                                   [effect, everyone]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Funktion zur Konvertierung von NLTK-POS-Tags zu WordNet-Tags\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)  # Standardmäßig Substantiv\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word, pos=get_wordnet_pos(word)) for word in data]\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: lemmatizer_on_text(x))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea45c9-1717-4f1a-94be-4e8cb623a169",
   "metadata": {},
   "source": [
    "CREATING TRAINING,VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5f8be885-a8f4-4658-9b91-e7dc8d1ba035",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.text\n",
    "y=data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9f1f690d-af04-4603-abf7-4455687bc660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 500)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 500\n",
    "tok = Tokenizer(num_words=5000)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "sequences_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6b511e39-5b4c-4ff4-8007-7ce8de3de64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(sequences_matrix, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22306f4d-892f-458c-8e6d-8020ba2f8bf2",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1bcacded-ee73-46c7-a299-262527092650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000,75,input_length=max_len))\n",
    "\n",
    "# Add the first LSTM layer\n",
    "#model.add(LSTM(64, return_sequences=True,recurrent_dropout=0.2,dropout=0.3))  # Return sequences to pass to the next LSTM layer\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "# Add a third LSTM layer\n",
    "model.add(LSTM(64,recurrent_dropout=0.2,dropout=0.5))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(64, activation='relu'))  # Intermediate dense layer for more learning capacity\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  # Dropout for dense layer\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # For classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  # Use sparse if labels are integers\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3d5ca050-fabb-4dc7-9c44-e1fc0bb13fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = EarlyStopping(monitor='val_accuracy',patience = 3 ,mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001)\n",
    "callbacks_lst = [checkpoint,reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa702ed-7d77-4e26-a414-669d5bc3c8bc",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9efcdbb9-729b-4bfa-8325-e58117208c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training on GPU...\") if tensorflow.config.list_physical_devices('GPU') else print(\"Training on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322c382-60ed-41c9-ba46-65e35f8159b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 280ms/step - accuracy: 0.5891 - loss: 0.6635 - val_accuracy: 0.7321 - val_loss: 0.6462 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.7473 - loss: 0.5179 - val_accuracy: 0.7396 - val_loss: 0.5514 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 284ms/step - accuracy: 0.7823 - loss: 0.4668 - val_accuracy: 0.7257 - val_loss: 0.5398 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 284ms/step - accuracy: 0.7985 - loss: 0.4416 - val_accuracy: 0.7146 - val_loss: 0.5711 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m 37/252\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 279ms/step - accuracy: 0.8115 - loss: 0.4199"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,batch_size=100,epochs=15, validation_split=0.1, callbacks=callbacks_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1064819-1b3d-48e4-ac49-7a440c81fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_loss = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig_loss.suptitle('Loss', fontsize=20)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84ce38-852c-452c-99b8-11cabadfe3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_accuracy = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='blue', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='green', label='val_accuracy')\n",
    "fig_accuracy.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72866b8-009e-4b23-a335-f5264271664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec7939-e137-491e-83c6-c854df531f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0193580-f1d3-4317-a15c-8b39f530a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('testing1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac579357-84db-4b36-93f3-de9e9bc52e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test) #getting predictions on the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd13c8-e2bc-4dfe-b2e1-f07f64bcfe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12729116-9ddd-45d7-a0ba-9054634a9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=['negative', 'positive'])\n",
    "model_lime = tensorflow.keras.models.load_model('testing1.keras')\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7464cf-77d7-47b5-a0f3-99dbcd6e5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(texts):\n",
    "    cleaned_texts = []\n",
    "    for text in texts:\n",
    "        text = short_conv(text)\n",
    "        text = text.lower()\n",
    "        text = cleaning_stopwords(text)\n",
    "        text = re.sub(userPattern,'', text)\n",
    "        text = re.sub(urlPattern,'', text)\n",
    "        text = re.sub(alphaPattern,' ', text)\n",
    "        text = cleaning_punctuations(text)\n",
    "        text = cleaning_repeating_char(text)\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = lemmatizer_on_text(text)\n",
    "        cleaned_texts.append(text)\n",
    "    tokenized_texts = tok.texts_to_sequences(cleaned_texts)\n",
    "    padded_texts = sequence.pad_sequences(tokenized_texts, maxlen=500)\n",
    "    return padded_texts\n",
    "\n",
    "def predict_proba(texts):\n",
    "    processed_texts = preprocess_texts(texts)  # Stellen Sie sicher, dass Texte verarbeitet werden\n",
    "    probabilities = model_lime.predict(processed_texts)  # Gibt eine Wahrscheinlichkeit pro Text\n",
    "    # Ergänzen der Wahrscheinlichkeit für die andere Klasse\n",
    "    probabilities = np.hstack((1 - probabilities, probabilities))\n",
    "    return probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe45b28-1237-45fc-b98e-6691fe368e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"This product is insane, keep the good work up @Logitech. I LOVE IT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb668b2-8e71-45b3-8b14-1de0dcc8a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(\n",
    "    example_text,\n",
    "    predict_proba,\n",
    "    num_features=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88d6e8-9491-4da3-979b-7ffe5a70c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82104ff-3221-43c5-8904-09b20b378d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
